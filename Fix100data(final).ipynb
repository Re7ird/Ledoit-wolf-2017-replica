{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39a951f0-75d6-4918-8b58-06dd1eb69251",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Answer Sheet for Question 3\n",
    "\n",
    "In this file, I used a fixed example to replicate Table 1 of ledoit and wolf(2017) paper. I cannot find the history stock list of the S&P 500 and the current components of the S&P500 do not have all the data I need from 1 Jan 1972 to 31 Dec 2011 (10094 trading days). There are only 26 stocks that have complete historical data of 10094 days, so I only use 1 time period of 271 returns.\n",
    "\n",
    "I use yfinance package to get the stock data and use numpy, pandas, sklearn to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "ad8beb15-fe20-45e5-aa06-9a957f7ebb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def showmatrixinfo(matrix):\n",
    "    print(\"Matrix shape: \",np.shape(matrix))\n",
    "    print(matrix)\n",
    "\n",
    "    #######This function is only for testing purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97197305-aeef-4abd-97de-748e4fa3f731",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stock selection and data acquisition\n",
    "\n",
    "I randomly pick 100 stocks for N=100 and save it to a csv file, then read and request the data from 1997-3-5 to 1998-4-1. If I cannot get full historical data of 272 days of one stock, I will pop out this stock and randomly replace it with another one.\n",
    "\n",
    "The time period \"1997-3-5 to 1998-4-1\" was picked by me manually. I looked at the historical S&P 500 index and the trend seems steady in this period. so I can assume that the distributions in these 272 days remain the same.\n",
    "\n",
    "This part(yfinance) requires internet connection. yfinance seems not working in the Chinese mainland. I actually used SCRP of the department to do all the coding. I run this file, save data, and download it to my local computer to double check. If yfinance is not available, you can jump to the next part after loading the return data which is already processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "f537bf5d-9472-40dd-a7ee-5ab7389428a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BA', 'BMY', 'CPB', 'CAT', 'CVX', 'KO', 'CL', 'COP', 'CVS', 'DE', 'DTE', 'EIX', 'ETR', 'EXC', 'XOM', 'F', 'GD', 'HAL', 'HIG', 'HSY', 'IBM', 'IP', 'KMB', 'KR', 'MRK', 'NSC', 'PEP', 'PFE', 'PPG', 'PG', 'PEG', 'SEE', 'SO', 'UNP', 'XEL', 'ABT', 'HON', 'AEP', 'SHW', 'CMI', 'EMR', 'SLB', 'CSX', 'CLX', 'GIS', 'NEM', 'MCD', 'LLY', 'BAX', 'BDX', 'JNJ', 'GPC', 'HPQ', 'WMB', 'JPM', 'IFF', 'AXP', 'BAC', 'CI', 'DIS', 'DUK', 'LNC', 'TAP', 'NEE', 'WFC', 'MMM', 'INTC', 'TGT', 'TXT', 'VFC', 'WBA', 'AIG', 'FDX', 'PCAR', 'ADP', 'MAS', 'GWW', 'ADM', 'WMT', 'SNA', 'SWK', 'MO', 'AAPL', 'OXY', 'CAG', 'BBWI', 'VZ', 'T', 'LOW', 'PHM', 'HES', 'LMT', 'HAS', 'BALL', 'APD', 'NUE', 'PKI', 'NOC', 'CNP', 'TJX']\n"
     ]
    }
   ],
   "source": [
    "def openfile(filename):\n",
    "    a=open(filename,'r')\n",
    "    b=a.readlines()\n",
    "    a.close()\n",
    "    return b\n",
    "\n",
    "stock=openfile(\"Fix100comp.csv\")\n",
    "stocklist=stock[0].replace(\"\\n\",\"\").split(\",\")\n",
    "print(stocklist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e626e438-0088-4cfd-a8f1-307822da600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "                Open     High       Low   Close  Adj Close    Volume\n",
      "Date                                                                \n",
      "1999-01-05  3.554688  3.71875  3.546875  3.6875   2.816108  10439200\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Date\n",
      "1999-01-05    2.816108\n",
      "Name: Adj Close, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "########This is only for test. If yfinance is not available, you can jump to next part after loading the already processed return data.\n",
    "stock=stocklist[0]\n",
    "print(yf.download(i, start=\"1999-1-5\", end=\"1999-1-6\"))                                            ##test\n",
    "print(yf.download(i, start=\"1999-1-5\", end=\"1999-1-6\").iloc[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25906323-7497-446f-90d5-297d9ebf7216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "(272, 6)\n"
     ]
    }
   ],
   "source": [
    "########Check data availability\n",
    "for i in stocklist:\n",
    "    data = yf.download(i, start=\"1997-3-5\", end=\"1998-4-2\")\n",
    "    print(data.shape)   #Check data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97c1aee2-34f6-4315-b75a-9f58317d0394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "######Generate price matrix(N,272),this will yields 271 returns from 1997-3-6 to 1998-4-1. yfinance will not return the data of the ending date.\n",
    "\n",
    "Pr=list()\n",
    "for i in stocklist:\n",
    "    data = yf.download(i, start=\"1997-3-5\", end=\"1998-4-2\")\n",
    "    ls=list(data.iloc[:,4])\n",
    "    Pr.append(ls)\n",
    "Pr=np.array(Pr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "3cab6543-039e-4c5d-a497-e95eea38ef76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 272)\n",
      "32.631103515625\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(Pr))        #check\n",
    "print(Pr[0,0])  ##Correct\n",
    "\n",
    "#Save file.\n",
    "np.savetxt(\"Price.txt\", Pr, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c12fa-fbf6-44b9-b71f-c2192568d0dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data processing and calculating returns.\n",
    "First, I calculate the return matrix of 271 days, then divide it into two parts: 270 days for estimating parameters, and 21 days for testing the results.\n",
    "\n",
    "The risk-free rate is from Ken French's Data Library, the same as FAMA-FRENCH covariance estimates. In the paper by Ledoit and Wolf(2017), they annualize returns linearly instead of using compound interest. So, I simply divided the risk-free rate by 250 to calculate the daily risk-free rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4e1204e-c6b2-4542-b5cf-1a794e4a0af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00238916  0.01916199 -0.00235089 ... -0.01463477  0.03217799\n",
      "   0.01199075]\n",
      " [-0.03610098  0.          0.01685407 ...  0.00678584  0.02267097\n",
      "   0.02119442]\n",
      " [ 0.01386943  0.00684016  0.02309794 ...  0.0042062  -0.00711211\n",
      "  -0.01652012]\n",
      " ...\n",
      " [ 0.00851838  0.01013458  0.00334456 ...  0.00120744  0.03679161\n",
      "   0.01803369]\n",
      " [-0.0374327   0.          0.         ...  0.00668137  0.0176998\n",
      "   0.0021737 ]\n",
      " [ 0.          0.00284913  0.         ... -0.03137801  0.02676057\n",
      "   0.03017811]]\n"
     ]
    }
   ],
   "source": [
    "Y1=Pr[:,1:]               ##Create a matrix only 271 days(day2-day272).\n",
    "Y2=Pr[:,:-1]               ##day1 to day271\n",
    "Yt=Y1/Y2-1\n",
    "print(Yt)                   #Yt is the return matrix of 100 stocks(271days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "9227ebfc-83df-4ed9-8dac-e56ccc1b8bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 250)\n",
      "(100, 21)\n"
     ]
    }
   ],
   "source": [
    "yt_est=Yt[:,:250]                     #yt for estimating covariance matrix(250days)\n",
    "yt_test=Yt[:,250:]                    #yt for testing the portfolio(21days)\n",
    "print(np.shape(yt_est))               \n",
    "print(np.shape(yt_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "6bc20eeb-dbee-4d65-819f-ea2fe4c51ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save data\n",
    "\n",
    "np.save(\"Fix100Stock_est_matrix.npy\",yt_est) #save matrix\n",
    "np.save(\"Fix100Stock_test_matrix.npy\",yt_test)\n",
    "np.savetxt(\"Fix100_Yt_est.csv\",yt_est,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485a3e3d-b6e1-4f57-a7e0-429a9317cb65",
   "metadata": {},
   "source": [
    "### All the codes below do not need internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "08f1e3c6-96df-408e-af3c-fe315ca36850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 250)\n",
      "(100, 21)\n",
      "(21,)\n",
      "[[ 0.01789964 -0.01992981  0.00358893 ... -0.01463477  0.03217799\n",
      "   0.01199075]\n",
      " [-0.01161362 -0.01051343  0.02499983 ...  0.00678584  0.02267097\n",
      "   0.02119442]\n",
      " [-0.00213677 -0.00535299  0.01399348 ...  0.0042062  -0.00711211\n",
      "  -0.01652012]\n",
      " ...\n",
      " [-0.00507116  0.00111554  0.02228419 ...  0.00120744  0.03679161\n",
      "   0.01803369]\n",
      " [ 0.          0.00722904  0.01435389 ...  0.00668137  0.0176998\n",
      "   0.0021737 ]\n",
      " [-0.01433089 -0.00484653  0.01623402 ... -0.03137801  0.02676057\n",
      "   0.03017811]]\n"
     ]
    }
   ],
   "source": [
    "#Load and check data\n",
    "\n",
    "yt_est=np.load(\"Fix100Stock_est_matrix.npy\")\n",
    "yt_test=np.load(\"Fix100Stock_test_matrix.npy\")\n",
    "\n",
    "FFdata = pd.read_csv('F-F_Research_Data_Factors_daily_Fix100.csv')\n",
    "rf_rate=FFdata.loc[250:,\"RF\"].to_numpy()\n",
    "rf_daily=rf_rate/250                          \n",
    "\n",
    "\n",
    "print(np.shape(yt_est))               \n",
    "print(np.shape(yt_test)) \n",
    "print(np.shape(rf_daily))\n",
    "print(yt_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d3a6b-094f-41a8-b7e1-f461cded9a8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Covariance Matrix Estimation\n",
    "\n",
    "I used different approaches to estimate the covariance matrix then define a function \"test_result\" to calculate the portfolio weight w, the return of 21 days and other estimators, then save it to a list.\n",
    "\n",
    "### 1/N\n",
    "This is 1/N approach. It assumes that every stock is not correlated. The covariance matrix is set to be I(N, N), which will yield equal portfolio weight as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "348e0d2f-84ef-4fb3-b81d-b8c466f809d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "w:\n",
      "[[0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "  0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      "  0.01 0.01]]\n",
      "(1, 21)\n",
      "\n",
      "1/N result:\n",
      "AV: 54.8711\n",
      "SD: 8.5095\n",
      "SR: 6.4482\n",
      "[54.87108271762652, 8.509538561633054, 6.448185447448784]\n"
     ]
    }
   ],
   "source": [
    "##     1/N Estimation\n",
    "\n",
    "N=100\n",
    "omega=np.identity(100)\n",
    "print(omega)\n",
    "\n",
    "def test_result(omega,method):\n",
    "    ### Use estimated covariance matrix to calculate w\n",
    "    \n",
    "    Omega= np.matrix(omega)\n",
    "    w=(Omega.I@np.ones((100,1)))/(np.ones((1,100))@Omega.I@np.ones((100,1)))\n",
    "    print(\"w:\")\n",
    "    print(w.T)\n",
    "    \n",
    "    ###########calculate payoff and excess payoff(ri-rf)\n",
    "    \n",
    "    payoff=w.T@yt_test*100\n",
    "    \n",
    "    exc_payoff=payoff-rf_daily\n",
    "    print(np.shape(exc_payoff))\n",
    "    ############Annualize:\n",
    "    \n",
    "    AV=exc_payoff.mean()*250\n",
    "    SD=exc_payoff.std()*pow(250,.5)\n",
    "    SR=AV/SD\n",
    "\n",
    "    print(\"\\n\"+method+\" result:\")\n",
    "    print(\"AV: {:.4f}\".format(AV))\n",
    "    print(\"SD: {:.4f}\".format(SD))\n",
    "    print(\"SR: {:.4f}\".format(SR))\n",
    "    return [AV,SD,SR]\n",
    "\n",
    "result1N=test_result(omega,\"1/N\")\n",
    "print(result1N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ae85c7-686a-4e97-9e6f-688d90558228",
   "metadata": {},
   "source": [
    "### Sample\n",
    "This is the Sample covariance matrix approach, the classical method for Markowitz's MPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "id": "2be9b96d-3ccd-49a3-8fd6-d50eb7bd0487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape:\n",
      "(100, 100)\n",
      "[[4.65997962e-04 1.63687852e-04 1.32154780e-04 ... 1.20673976e-04\n",
      "  6.87962711e-05 1.69091373e-04]\n",
      " [1.63687852e-04 5.05786101e-04 2.03311377e-04 ... 1.04776241e-04\n",
      "  8.67511550e-05 1.68726755e-04]\n",
      " [1.32154780e-04 2.03311377e-04 3.68006616e-04 ... 1.01790305e-04\n",
      "  5.12305790e-05 1.23077641e-04]\n",
      " ...\n",
      " [1.20673976e-04 1.04776241e-04 1.01790305e-04 ... 4.23508458e-04\n",
      "  3.99773908e-05 9.01986996e-05]\n",
      " [6.87962711e-05 8.67511550e-05 5.12305790e-05 ... 3.99773908e-05\n",
      "  2.24052101e-04 5.58509147e-05]\n",
      " [1.69091373e-04 1.68726755e-04 1.23077641e-04 ... 9.01986996e-05\n",
      "  5.58509147e-05 5.87914599e-04]]\n",
      "w:\n",
      "[[ 0.00782784 -0.00789738 -0.09516237  0.01701728  0.02315577 -0.05797588\n",
      "   0.00686327  0.02343564  0.00105536  0.00082359  0.13517302 -0.05073402\n",
      "   0.01183255  0.0154362  -0.07560041  0.01889112  0.04293443  0.03592357\n",
      "   0.04300626 -0.02095569  0.01702989 -0.04232427 -0.00591592 -0.00339875\n",
      "   0.0185084  -0.05853328 -0.00148419 -0.00536898 -0.00245309 -0.02344836\n",
      "   0.03318052  0.09043834 -0.02151486  0.06562489  0.1115352  -0.05136415\n",
      "  -0.05209073  0.16755467 -0.01787846 -0.0111262   0.03555239 -0.05952679\n",
      "   0.01215287  0.05029678  0.10180839  0.01085416  0.0552036  -0.01624072\n",
      "   0.01607923 -0.05519632 -0.00199431  0.08829938 -0.0158331   0.00021565\n",
      "   0.04885882  0.04601749 -0.0852429  -0.04324233  0.00321163  0.04825594\n",
      "   0.05032211  0.01303825  0.01258747  0.19318203 -0.11238622  0.06550619\n",
      "   0.02256591 -0.01247741 -0.02235849  0.04075087  0.02024801 -0.00945258\n",
      "  -0.00041934 -0.01756989  0.0202482   0.05656775  0.04895535  0.05053103\n",
      "   0.03005697  0.06873219 -0.0474797  -0.05031258  0.01740403  0.03762351\n",
      "   0.00741378 -0.02364179  0.0303726  -0.08896878  0.01532694  0.02138778\n",
      "  -0.01201683  0.04369983  0.02430442 -0.00785203  0.05518467  0.01091834\n",
      "   0.00777949  0.03403699 -0.08633722 -0.02902251]]\n",
      "(1, 21)\n",
      "\n",
      "Samp result:\n",
      "AV: 55.5981\n",
      "SD: 10.2866\n",
      "SR: 5.4049\n",
      "[55.598106763739665, 10.286575290190576, 5.404919051801313]\n"
     ]
    }
   ],
   "source": [
    "##     Sample Covariance Estimation\n",
    "omega=np.cov(yt_est)\n",
    "print(\"Matrix shape:\")\n",
    "print(np.shape(omega))\n",
    "print(omega)\n",
    "\n",
    "resultSamp=test_result(omega,\"Samp\")\n",
    "print(resultSamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b267b759-95ac-4326-8d0a-74b87aa05ee7",
   "metadata": {},
   "source": [
    "### Lin\n",
    "This is the linear shrinkage approach. The matrix is given by the linear shrinkage estimator of Ledoit and Wolf(2004). While I googled the method, I found out that sklern package has this method, which will return the matrix and coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "939a1743-4446-418a-ab7c-0fd2471daf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape:\n",
      "(100, 100)\n",
      "[[4.54553244e-04 1.49775906e-04 1.20922852e-04 ... 1.10417810e-04\n",
      "  6.29492276e-05 1.54720178e-04]\n",
      " [1.49775906e-04 4.90959761e-04 1.86031800e-04 ... 9.58712347e-05\n",
      "  7.93781133e-05 1.54386550e-04]\n",
      " [1.20922852e-04 1.86031800e-04 3.64890251e-04 ... 9.31390750e-05\n",
      "  4.68764560e-05 1.12617186e-04]\n",
      " ...\n",
      " [1.10417810e-04 9.58712347e-05 9.31390750e-05 ... 4.15674953e-04\n",
      "  3.65796842e-05 8.25326486e-05]\n",
      " [6.29492276e-05 7.93781133e-05 4.68764560e-05 ... 3.65796842e-05\n",
      "  2.33170532e-04 5.11041061e-05]\n",
      " [1.54720178e-04 1.54386550e-04 1.12617186e-04 ... 8.25326486e-05\n",
      "  5.11041061e-05 5.66108100e-04]]\n",
      "w:\n",
      "[[ 0.00494146 -0.01270759 -0.06927698  0.00851496  0.01040177 -0.04685151\n",
      "   0.00359105  0.03074149  0.01736969  0.00644099  0.08450095 -0.01903434\n",
      "   0.02569077  0.02607242 -0.06068882  0.0170703   0.04465801  0.02245166\n",
      "   0.03334027 -0.00903853  0.01280188 -0.03183679 -0.0098643   0.00321426\n",
      "   0.02038573 -0.03732696 -0.00243112 -0.01685952 -0.01737469 -0.01633966\n",
      "   0.04288008  0.08113585  0.0129613   0.05799822  0.08605447 -0.03668831\n",
      "  -0.04998557  0.1192352  -0.01183035 -0.0060419   0.0279789  -0.04264014\n",
      "  -0.00457961  0.0418138   0.08401007  0.01666391  0.04487457 -0.01292215\n",
      "   0.01039077 -0.03697024 -0.00217961  0.07371464 -0.02052724  0.00660365\n",
      "   0.02643957  0.03827219 -0.05413801 -0.02888149  0.00699141  0.03513641\n",
      "   0.05802357  0.00898084  0.01225911  0.12716319 -0.08771622  0.06183256\n",
      "   0.02044536 -0.0230815  -0.02445738  0.04023846  0.00809409 -0.01846113\n",
      "  -0.00710368 -0.01924176  0.01954283  0.05453143  0.04908636  0.04420414\n",
      "   0.02237832  0.05212305 -0.03662288 -0.04694079  0.01974826  0.03423801\n",
      "  -0.00386326 -0.00582372  0.02352845 -0.05909679  0.01841432  0.01028742\n",
      "  -0.00460075  0.05398129  0.02727447  0.00519751  0.05710414  0.01526284\n",
      "   0.00338475  0.0280039  -0.0463151  -0.02033095]]\n",
      "(1, 21)\n",
      "\n",
      "Lin result:\n",
      "AV: 61.4428\n",
      "SD: 8.4146\n",
      "SR: 7.3019\n",
      "[61.4427844131374, 8.414576989113774, 7.301945717845119]\n"
     ]
    }
   ],
   "source": [
    "##     Lin(Ledoit-Wolf 2004 methpd) shrinkage Estimation\n",
    "from sklearn.covariance import ledoit_wolf\n",
    "\n",
    "omega=ledoit_wolf(yt_est.T)[0]\n",
    "print(\"Matrix shape:\")\n",
    "print(np.shape(omega))\n",
    "print(omega)\n",
    "\n",
    "resultLin=test_result(omega,\"Lin\")\n",
    "print(resultLin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b24f6d2-1951-4798-9a84-19a61efcd9ad",
   "metadata": {},
   "source": [
    "### NonLin\n",
    "This is the Non-Linear shrinkage estimate procedure. I followed the procedure of the reference paper. The estimator of s(x) is tricky. I cannot find the exact answer to it. The appendix of the paper provides more details but still, it's too obscure to me. \n",
    "\n",
    "I calculated the eigenvalue and eigenvector of the sample covariance matrix. I found out that all the eigenvalues are greater than 0 so I typed in the formula of dt_est. the dt_est needs the Bona fide estimator of s(x), this is the only part missing.\n",
    "\n",
    "Atfer calculate the dt_est I can generate the diagonal matrix Dt_est and calculate the shrinked covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "c7fe5566-887f-42d9-ada3-6ce5f554fe23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "[1.04849396e-02 2.07206190e-03 1.22446716e-03 1.05311187e-03\n",
      " 8.50372217e-04 8.01669911e-04 7.26188092e-04 6.61691751e-04\n",
      " 6.40603148e-04 5.79258139e-04 5.53521133e-04 5.21068570e-04\n",
      " 5.13918365e-04 4.77888500e-04 4.64027697e-04 4.32263165e-04\n",
      " 4.30368419e-04 4.17645204e-04 3.89741055e-04 3.81923847e-04\n",
      " 3.67552165e-04 3.56383301e-04 3.44262903e-04 3.31074478e-04\n",
      " 3.22949962e-04 3.19421370e-04 3.05411200e-04 2.90897615e-04\n",
      " 2.86010302e-04 2.79226258e-04 2.73481584e-04 2.58810708e-04\n",
      " 2.50172175e-04 2.45675555e-04 2.47093906e-04 2.33387745e-04\n",
      " 2.23582988e-04 2.20511269e-04 2.05509713e-04 2.05076278e-04\n",
      " 2.02980294e-04 1.93337973e-04 1.87443746e-04 1.83908938e-04\n",
      " 1.79125410e-04 1.75009206e-04 1.73018291e-04 1.62776371e-04\n",
      " 1.60689509e-04 1.53407900e-04 1.50189592e-04 1.46828050e-05\n",
      " 1.45326456e-04 1.40554700e-04 1.39579652e-04 1.36752426e-04\n",
      " 1.71542677e-05 1.90265545e-05 1.32473692e-04 1.26936350e-04\n",
      " 2.29724333e-05 2.40164448e-05 1.22693385e-04 1.21822920e-04\n",
      " 2.71413097e-05 1.16769149e-04 1.14896577e-04 1.11464322e-04\n",
      " 1.07908594e-04 1.05030227e-04 3.00872020e-05 3.15546349e-05\n",
      " 1.01401560e-04 3.52739572e-05 3.66650901e-05 3.90441426e-05\n",
      " 4.05196031e-05 4.22859845e-05 4.32756291e-05 4.53465357e-05\n",
      " 4.85370696e-05 4.98125787e-05 9.42463335e-05 9.23276987e-05\n",
      " 8.96670663e-05 8.81713531e-05 5.27660538e-05 5.50097677e-05\n",
      " 5.75868805e-05 5.86789610e-05 6.10819073e-05 6.37883515e-05\n",
      " 8.34764175e-05 6.70963967e-05 6.86021440e-05 7.99644558e-05\n",
      " 7.91078606e-05 7.60468516e-05 7.24253962e-05 7.42232207e-05]\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nomega=Ut@Dt_est@Ut.T\\n\\nresult_NonLin=test_result(omega,\"NonLin\")\\n'"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##     NonLin shrinkage Estimation\n",
    "from sympy import *\n",
    "\n",
    "##get eigenvalue and vector\n",
    "eigenvalue, eigenvector = np.linalg.eig(np.cov(yt_est))\n",
    "print(eigenvalue>0)          \n",
    "\n",
    "##   Test reult: All eigenvalues are greater than 0\n",
    "print(eigenvalue)\n",
    "\n",
    "Ut=np.mat(eigenvector)\n",
    "\n",
    "######## test ####    Ut is verified.\n",
    "print(np.allclose(Ut.T,Ut.I))\n",
    "\n",
    "####Shrink eigenvalue calculation(unfinished):\n",
    "\n",
    "c=0.4                   #c=N/T according to bona fide\n",
    "\n",
    "def s(eigenvalue):             ## This is the estimator of the Stieltjes Transform s(x)\n",
    "    s = symbols('s')\n",
    "    solve(,s)  ##This is the missing part of my replication.....\n",
    "    \n",
    "    return s\n",
    "    \n",
    "#generate diagonal matrix dt_est:\n",
    "\n",
    "#dt_est[i]=1/(eigenvalue[i]*(abs(s(eigenvalue[i])))^2)  \n",
    "#Dt_est=np.diag(dt_est)      #This is the diagonal matrix of Dt estimate.\n",
    "\n",
    "\n",
    "'''\n",
    "omega=Ut@Dt_est@Ut.T\n",
    "\n",
    "result_NonLin=test_result(omega,\"NonLin\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a2fbcc-d7b3-4e5b-8f3e-d63486f9c444",
   "metadata": {},
   "source": [
    "### SF\n",
    "This is the single-factor model. First, I generate factors using an equal-weighted portfolio. Then, I calculate the factor variance and covariance of the factor and single stock. I also saved the data and run it in STATA to check if I'm right. The covariance of stock i and j is equal to $ \\frac{beta1 * beta2}{var(factor)} $ if $ i \\neq j $, the diagonals need to be replaced by var(ri) or add the variance of residuals.  (I'm not familiar with LATEX, still working on it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "c16b84ed-21e0-4032-84c8-329a58a27fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal portfolio:  (1, 100)\n",
      "Factor matrix shape:  (1, 250)\n",
      "Matrix shape:  (100, 100)\n",
      "[[4.65997962e-04 1.82112016e-04 1.64998702e-04 ... 1.01471267e-04\n",
      "  7.28569689e-05 1.56005464e-04]\n",
      " [1.82112016e-04 5.05786101e-04 1.92200615e-04 ... 1.18199960e-04\n",
      "  8.48682692e-05 1.81724739e-04]\n",
      " [1.64998702e-04 1.92200615e-04 3.68006616e-04 ... 1.07092549e-04\n",
      "  7.68930823e-05 1.64647818e-04]\n",
      " ...\n",
      " [1.01471267e-04 1.18199960e-04 1.07092549e-04 ... 4.23508458e-04\n",
      "  4.72878781e-05 1.01255480e-04]\n",
      " [7.28569689e-05 8.48682692e-05 7.68930823e-05 ... 4.72878781e-05\n",
      "  2.24052101e-04 7.27020323e-05]\n",
      " [1.56005464e-04 1.81724739e-04 1.64647818e-04 ... 1.01255480e-04\n",
      "  7.27020323e-05 5.87914599e-04]]\n",
      "w:\n",
      "[[-0.01158836 -0.02306372 -0.02402899 -0.00370027 -0.00331666 -0.0299433\n",
      "  -0.01534953  0.02758373  0.00984259 -0.00257735  0.08203581  0.04367178\n",
      "   0.06361238  0.03669402 -0.01863309  0.0049561   0.03350595 -0.00591081\n",
      "   0.01912271 -0.00575308 -0.01568702 -0.00409937 -0.00500743  0.00762265\n",
      "  -0.01274834 -0.01112693 -0.0104716  -0.03266031 -0.0056785  -0.0251494\n",
      "   0.07113103  0.0227373   0.06817781  0.02821926  0.12569628 -0.0125684\n",
      "  -0.02696771  0.16711027 -0.00379695 -0.00452559  0.00108262 -0.01267278\n",
      "  -0.00205376  0.02274327  0.06927911  0.00744027  0.0192874  -0.0236994\n",
      "  -0.02205936 -0.0112524  -0.01448911  0.03565715 -0.01142122  0.02153278\n",
      "  -0.01652303  0.01408569 -0.03188988 -0.01666446  0.01862662 -0.00602953\n",
      "   0.08476192  0.01607915  0.00425212  0.15286387 -0.03632339  0.01868619\n",
      "  -0.00961972 -0.0229491  -0.00597597  0.03630947 -0.01187847 -0.02507079\n",
      "  -0.0103294  -0.01505605  0.00622211  0.03487612  0.03597644  0.0128161\n",
      "  -0.0057939   0.02917841 -0.00704398 -0.01203856  0.00284533  0.03041384\n",
      "  -0.01559903  0.01450696  0.02104634  0.01216961  0.00654439 -0.01113545\n",
      "   0.0097932   0.03391086  0.00973953  0.00800219  0.03021892  0.00135131\n",
      "   0.00181326  0.00891934  0.03537684 -0.00820694]]\n",
      "(1, 21)\n",
      "\n",
      "SF result:\n",
      "AV: 94.5516\n",
      "SD: 10.0423\n",
      "SR: 9.4153\n"
     ]
    }
   ],
   "source": [
    "##     Single factor estimation\n",
    "##   First, estimate SigmaF=Cov(betai,betaj)\n",
    "\n",
    "##   Generate Factor\n",
    "equalw=np.array([[0.01]*100])\n",
    "print(\"equal portfolio: \",np.shape(equalw))\n",
    "factor=equalw@yt_est\n",
    "print(\"Factor matrix shape: \",np.shape(factor))\n",
    "\n",
    "\n",
    "##estimate SigmaF\n",
    "var_f=np.var(factor,ddof=1)      #variance of factor,\n",
    "\n",
    "np.savetxt(\"SF_factor.csv\",factor,delimiter=\",\")\n",
    "\n",
    "##compute cov(Ri,Rf),the covariance of stocks and factor\n",
    "var_if=np.cov(yt_est,factor)[-1,:-1]\n",
    "var_if=np.matrix(var_if)          #convert to 1X100 matrix\n",
    "\n",
    "\n",
    "\n",
    "SigmaF=var_if.T*var_if/var_f  \n",
    "\n",
    "##The elements of diagonal need to change to var(ri) ,or betai^2*var_f + var(residual)\n",
    "\n",
    "for i in range(100):\n",
    "    SigmaF[i,i]=np.cov(yt_est)[i,i]\n",
    "\n",
    "\n",
    "showmatrixinfo(SigmaF)    ####Seems correct\n",
    "\n",
    "\n",
    "resultSF=test_result(SigmaF,\"SF\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec633a-0995-4d9c-bd9c-4a8829f057fc",
   "metadata": {},
   "source": [
    "### FF\n",
    "In the Fama and French model, I also downloaded the data from Ken French's Data Library as Ledoit and Wolf did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "e7d0a354-2f31-43ef-aa63-6d9a802e146b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta matrix:  (100, 3)\n",
      "SigmaF: \n",
      "Matrix shape:  (100, 100)\n",
      "[[4.65997962e-04 1.81657701e-04 1.58188346e-04 ... 9.14582713e-05\n",
      "  6.18714905e-05 1.49341589e-04]\n",
      " [1.81657701e-04 5.05786101e-04 1.88232657e-04 ... 1.09899032e-04\n",
      "  7.61206669e-05 1.69057593e-04]\n",
      " [1.58188346e-04 1.88232657e-04 3.68006616e-04 ... 9.76882145e-05\n",
      "  6.98722984e-05 1.50011922e-04]\n",
      " ...\n",
      " [9.14582713e-05 1.09899032e-04 9.76882145e-05 ... 4.23508458e-04\n",
      "  4.13773752e-05 8.71241591e-05]\n",
      " [6.18714905e-05 7.61206669e-05 6.98722984e-05 ... 4.13773752e-05\n",
      "  2.24052101e-04 6.03188208e-05]\n",
      " [1.49341589e-04 1.69057593e-04 1.50011922e-04 ... 8.71241591e-05\n",
      "  6.03188208e-05 5.87914599e-04]]\n",
      "w:\n",
      "[[-0.00585698 -0.02128737 -0.02309375 -0.00118393 -0.00131329 -0.03139742\n",
      "  -0.01006522  0.02712724  0.00972651  0.003003    0.07766524  0.03425162\n",
      "   0.06072673  0.03405158 -0.01084858 -0.00914393  0.03725362 -0.00071683\n",
      "   0.00899339 -0.00621549 -0.00516377 -0.00790941 -0.00377452  0.00597547\n",
      "  -0.01203261  0.00153645 -0.00334065 -0.02617199 -0.00901608 -0.01499144\n",
      "   0.06541306  0.0209107   0.05724226  0.02768586  0.11812905 -0.00480978\n",
      "  -0.01731636  0.1525883  -0.00204015 -0.00048198 -0.00386688 -0.00662922\n",
      "   0.0019866   0.01761173  0.07379777  0.01347429  0.02322043 -0.01993699\n",
      "  -0.02128524 -0.00939122 -0.01747465  0.04431451  0.00247952  0.0277388\n",
      "  -0.04594474  0.01073434 -0.04969723 -0.04262159  0.01475807 -0.00281632\n",
      "   0.08078883 -0.00581069  0.0072427   0.14409214 -0.05852004  0.02037121\n",
      "   0.00823767 -0.01815945 -0.00790817  0.03002153 -0.00632484 -0.04301393\n",
      "  -0.00746918 -0.01563264  0.0180706   0.03364858  0.03492973  0.02018941\n",
      "  -0.00068004  0.03098395 -0.00351805 -0.00659201  0.00698275  0.02779652\n",
      "  -0.01073291  0.02505041  0.02085031  0.01044931  0.00742803 -0.01478517\n",
      "   0.01821873  0.0372308   0.00774262  0.01181999  0.02414934  0.0054596\n",
      "   0.00462697  0.0094911   0.0322994  -0.00358569]]\n",
      "(1, 21)\n",
      "\n",
      "FF result:\n",
      "AV: 89.1074\n",
      "SD: 8.6302\n",
      "SR: 10.3250\n"
     ]
    }
   ],
   "source": [
    "##     FAMA FRENCH estimation\n",
    "\n",
    "#####First, Generate 3-factors array.\n",
    "import pandas as pd\n",
    "FFdata = pd.read_csv('F-F_Research_Data_Factors_daily_Fix100.csv')\n",
    "index=[\"Mkt-RF\",\"SMB\",\"HML\"]\n",
    "FFfactors=FFdata.loc[:249,index].to_numpy()\n",
    "#showmatrixinfo(FFfactors)                #####Done\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "LG=LinearRegression()\n",
    "\n",
    "LG.fit(FFfactors,yt_est.T)      ##FFfactor matirx is a (250,3) matrix!\n",
    "betas=LG.coef_\n",
    "print(\"Beta matrix: \",np.shape(betas))\n",
    "\n",
    "var_ff=np.cov(FFfactors.T)      ##Covariance of FAMA FRENCH 3 Factor model.\n",
    "\n",
    "SigmaF=betas@var_ff@betas.T\n",
    "\n",
    "###As same as SF, the diagonal need add residual,or replace by var(Ri)\n",
    "\n",
    "for i in range(100):\n",
    "    SigmaF[i,i]=np.cov(yt_est)[i,i]\n",
    "    \n",
    "print(\"SigmaF: \")\n",
    "showmatrixinfo(SigmaF)\n",
    "\n",
    "resultFF=test_result(SigmaF,\"FF\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d9febc-5068-4cbb-ba25-d060ac8a18d7",
   "metadata": {},
   "source": [
    "### POET\n",
    "This is the POET estimation of covariance matrix by Fan et al. (2013). I use PCA from sklearn to generate 5 factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "0cd2f9a2-40dc-46e8-bdf1-fc6f681b11d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating components:\n",
      "PCA Componets:\n",
      " [[-0.03258095 -0.03888459 -0.0065898  ...  0.00327815 -0.06768189\n",
      "   0.00408442]\n",
      " [-0.02718246 -0.00858614 -0.06876589 ...  0.01374791  0.02649288\n",
      "  -0.01126418]\n",
      " [ 0.04822549 -0.05586383 -0.0338755  ...  0.01011372  0.05182732\n",
      "   0.05259222]\n",
      " [ 0.01281936  0.00725788  0.07087674 ... -0.06776106 -0.00534046\n",
      "  -0.00301675]\n",
      " [ 0.03553163  0.07364333  0.06746965 ... -0.0111177   0.09713746\n",
      "   0.07164584]]\n",
      "(5, 250)\n",
      "\n",
      "Eigenvalues: [0.00521385 0.00365524 0.00307917 0.00236818 0.00214257]\n",
      "Variance explaination: [0.08228226 0.05768501 0.04859386 0.03737338 0.03381289]\n",
      "Add up:  0.2597474094171566\n",
      "\n",
      "Regression:\n",
      "Beta matrix:  (100, 5)\n",
      "Matrix shape:  (100, 100)\n",
      "[[4.65997962e-04 1.63375681e-04 1.08053351e-04 ... 5.98541791e-05\n",
      "  6.68605577e-06 1.32445330e-04]\n",
      " [1.63375681e-04 5.05786101e-04 1.48057214e-04 ... 7.78681965e-05\n",
      "  2.23009885e-05 1.63153519e-04]\n",
      " [1.08053351e-04 1.48057214e-04 3.68006616e-04 ... 4.90447769e-05\n",
      "  9.45440735e-06 1.08309142e-04]\n",
      " ...\n",
      " [5.98541791e-05 7.78681965e-05 4.90447769e-05 ... 4.23508458e-04\n",
      "  8.26614955e-06 5.11021203e-05]\n",
      " [6.68605577e-06 2.23009885e-05 9.45440735e-06 ... 8.26614955e-06\n",
      "  2.24052101e-04 7.90819013e-06]\n",
      " [1.32445330e-04 1.63153519e-04 1.08309142e-04 ... 5.11021203e-05\n",
      "  7.90819013e-06 5.87914599e-04]]\n",
      "w:\n",
      "[[-0.00797665 -0.02009149 -0.00069322  0.00171859  0.0078706  -0.00671633\n",
      "  -0.00375301  0.02338729  0.00495079  0.00021987  0.05283407  0.03558326\n",
      "   0.04412857  0.02904249  0.00314141  0.00878285  0.01539529  0.00013134\n",
      "   0.01497504  0.00185569 -0.01632973  0.00304617  0.00386709  0.01109242\n",
      "  -0.01444013  0.00091128  0.00018804 -0.02440244  0.00981194 -0.00809328\n",
      "   0.04619979  0.01472856  0.05092595  0.01781768  0.06559776 -0.00291165\n",
      "  -0.00565659  0.0891456   0.00092774 -0.00225301  0.00460303 -0.00138788\n",
      "   0.00736266  0.01656993  0.03265493  0.02806141  0.01376147 -0.0198725\n",
      "  -0.0175616   0.00122025 -0.00475519  0.01968342 -0.00616616  0.01884074\n",
      "  -0.00260338  0.00831465 -0.00924576 -0.00566283  0.01271824  0.00193682\n",
      "   0.05208998  0.01529178  0.00188189  0.08601722 -0.00660276  0.01057174\n",
      "  -0.0145909  -0.00679053  0.00651399  0.02074697  0.00078935 -0.00112069\n",
      "  -0.00163832 -0.02123703  0.00825986  0.02398796  0.02080347  0.0105295\n",
      "  -0.00177774  0.02331131  0.00037729  0.00181266  0.02954241  0.02547347\n",
      "  -0.00041045  0.0151659   0.01847592  0.01620886  0.00850942 -0.00197754\n",
      "   0.01678682  0.02184979  0.00837406  0.00879341  0.01742913  0.00429728\n",
      "   0.0037631   0.00680255  0.02893664 -0.00067965]]\n",
      "(1, 21)\n",
      "\n",
      "POET result:\n",
      "AV: 89.6868\n",
      "SD: 7.8710\n",
      "SR: 11.3946\n"
     ]
    }
   ],
   "source": [
    "### POET estimation\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn import preprocessing\n",
    "from sklearn import datasets\n",
    "\n",
    "print(\"generating components:\")\n",
    "pca = PCA(n_components=5, copy=True)\n",
    "pca.fit(yt_est)\n",
    "factors=pca.components_\n",
    "print('PCA Componets:\\n', pca.components_)\n",
    "print(np.shape(pca.components_))\n",
    "print('\\nEigenvalues:', pca.explained_variance_)\n",
    "print('Variance explaination:', pca.explained_variance_ratio_)\n",
    "print(\"Add up: \",np.sum(pca.explained_variance_ratio_))\n",
    "\n",
    "\n",
    "##Regression:\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"\\nRegression:\")\n",
    "LG2=LinearRegression()\n",
    "\n",
    "LG2.fit(factors.T,yt_est.T)\n",
    "betas=LG2.coef_\n",
    "print(\"Beta matrix: \",np.shape(betas))\n",
    "\n",
    "var_fs=np.cov(factors)\n",
    "\n",
    "SigmaF=betas@var_fs@betas.T\n",
    "\n",
    "###As same as SF, the diagonal need add residual,or replace by var(Ri)\n",
    "\n",
    "for i in range(100):\n",
    "    SigmaF[i,i]=np.cov(yt_est)[i,i]\n",
    "    \n",
    "showmatrixinfo(SigmaF)\n",
    "\n",
    "resultPOET=test_result(SigmaF,\"POET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52ad47-a446-44a2-b089-62264dcfd5b8",
   "metadata": {},
   "source": [
    "## Final Results\n",
    "This is all the result I estimated above. I made a tab similar to the original one in Ledoit and Wolf(2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "3813b83e-b116-4efc-ac64-5c4dc6436b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1\n",
      "Performance measures for various estimators of the GMV portfolio\n",
      "Period: January 19, 1973 to December 31, 2011\" \n",
      "\t1/N \tSample \tLin \tNolin \tSF \tFF \tPOET \tNL-SF\n",
      "----------------------------------------------------------------------\n",
      "                                N=100                                 \n",
      "----------------------------------------------------------------------\n",
      "AV \t54.87 \t55.60\t61.44\t\t94.55\t89.11\t89.69\n",
      "SD \t8.51 \t10.29\t8.41\t\t10.0\t8.63\t7.87\n",
      "SR \t6.45 \t5.40\t7.30\t\t9.42\t10.33\t11.39\n"
     ]
    }
   ],
   "source": [
    "#####Show all the results\n",
    "\n",
    "def prtb(result1N,resultSamp,resultLin,resultNonLin,resultSF,resultFF,resultPOET):\n",
    "    print(\"Table 1\")\n",
    "    print(\"Performance measures for various estimators of the GMV portfolio\")\n",
    "    print(\"{}\".format('''Period: January 19, 1973 to December 31, 2011\" '''))\n",
    "    print(\"\\t1/N \\tSample \\tLin \\tNolin \\tSF \\tFF \\tPOET \\tNL-SF\")\n",
    "    print(\"{:-^70}\".format(\"\"))\n",
    "    print(\"{:^70}\".format(\"N=100\"))\n",
    "    print(\"{:-^70}\".format(\"\"))\n",
    "    print(\"AV \\t{:.2f} \\t{:.2f}\\t{:.2f}\\t{}\\t{:.2f}\\t{:.2f}\\t{:.2f}\".format(result1N[0],resultSamp[0],resultLin[0],\"\",resultSF[0],resultFF[0],resultPOET[0]))\n",
    "    print(\"SD \\t{:.2f} \\t{:.2f}\\t{:.2f}\\t{}\\t{:.1f}\\t{:.2f}\\t{:.2f}\".format(result1N[1],resultSamp[1],resultLin[1],\"\",resultSF[1],resultFF[1],resultPOET[1]))\n",
    "    print(\"SR \\t{:.2f} \\t{:.2f}\\t{:.2f}\\t{}\\t{:.2f}\\t{:.2f}\\t{:.2f}\".format(result1N[2],resultSamp[2],resultLin[2],\"\",resultSF[2],resultFF[2],resultPOET[2]))\n",
    "    return\n",
    "\n",
    "\n",
    "prtb(result1N,resultSamp,resultLin,[],resultSF,resultFF,resultPOET)"
   ]
  },
  {
   "attachments": {
    "3f2ff775-6e53-4996-ad8b-b08933485f81.png": {
     "image/png": "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"
    },
    "8276d181-1da9-433c-b3c5-0d31664ea2c9.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5612def1-f57c-4272-bc3f-701ff09286c6",
   "metadata": {},
   "source": [
    "## Summary\n",
    "About the missing part(Bina fide estimator of s(x)), I check appendix B of the paper. I was hoping to get a clear answer to the estimator function of s(x), but I cannot find it in the appendix. I checked Ledoit and Wolf(2012) and Ledoit and Wolf(2015). The math is even more complicated in these two papers and It's different from the appendix of Ledoit and Wolf(2017).\n",
    "\n",
    "The solution is to use a QuEST function to discretize the original equation. This will transform the integral form into a sum form.\n",
    "\n",
    "![image.png](attachment:3f2ff775-6e53-4996-ad8b-b08933485f81.png)\n",
    "\n",
    "and the tau:\n",
    "\n",
    "![image.png](attachment:8276d181-1da9-433c-b3c5-0d31664ea2c9.png)\n",
    "\n",
    "The tau is linked to the q(v), this is where I got completely lost.\n",
    "\n",
    "It seems that I need to get the q(v) and use some solving packages to solve tau, then s(x).\n",
    "\n",
    "I cannot understand the formula and how to solve it using python. I don't even know if I'm thinking it right.\n",
    "\n",
    "## About this project\n",
    "I did all the coding myself on the SCRP of the department mainly because yfinance is not available in mainland China and I'm not in HK this week. Happy new year btw:) The platform is really great and I found out that pynotebook is a great tool to do it. It's much more interesting to code and write in blocks. I even learned some LATEX to type formulas. \n",
    "\n",
    "I mainly use csv to do the IO, and I also used some .npy files to save numpy matrix. csv files can be loaded in excel so I can use excel, stata to calculate certain numbers to check if I coded them right.\n",
    "\n",
    "I transformed all the data into matrixes and calculate them using linear algebra. I use certain packages to estimate parameters(mainly sklearn)\n",
    "\n",
    "## References\n",
    "About reference, I did all the coding myself, but I referenced a lot of materials.\n",
    "I learned numpy, pandas and sklearn through internet, including google, baidu, youtube, bilibili, and manuals of these packages.\n",
    "I also referenced the methods in the article on the internet and some textbooks.\n",
    "\n",
    "### Papers:  \n",
    "Fama, E. F. and K. R. French. 1993. Common risk factors in the returns on stocks and bonds.\n",
    "Journal of Financial Economics 33: 3–56.  \n",
    "\n",
    "Fan, J., Y. Liao, and M. Mincheva. 2013. Large covariance estimation by thresholding\n",
    "principal orthogonal complements (with discussion). Journal of the Royal Statistical Society,\n",
    "Series B 75: 603–680.  \n",
    "\n",
    "Ledoit, O. and M. Wolf. 2004b. A well-conditioned estimator for large-dimensional covariance matrices. Journal\n",
    "of Multivariate Analysis 88: 365–411. \n",
    "\n",
    "Ledoit, O. and M. Wolf. 2012. Nonlinear shrinkage estimation of large-dimensional covariance matrices. Annals\n",
    "of Statistics 40: 1024–1060.  \n",
    "\n",
    "Ledoit, O. and M. Wolf. 2015. Spectrum estimation: a unified framework for covariance matrix estimation and\n",
    "PCA in large dimensions. Journal of Multivariate Analysis 139: 360–384\n",
    "\n",
    "Markowitz, H. 1952. Portfolio selection. Journal of Finance 7: 77–91"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
